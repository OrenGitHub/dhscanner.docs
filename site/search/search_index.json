{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Hi you magnificent thing ! We're glad to see you here at dhscanner !</p>"},{"location":"contribution/usage/","title":"Usage","text":"<p>The best way to contribute is by starting to battle-test it and expose all kinds of real life scenarios</p>"},{"location":"dhscanner_internals/design/","title":"Design","text":"<p>Hi you magnificent thing ! We're happy to see you here !</p>"},{"location":"dhscanner_internals/rules/","title":"Atoms","text":"<p>Code facts are represented by predicates and varaibles. For the most part, variables are just code locations. Start line, start column, end line and end column. In addition, the filename itself is also a part of the variable name. Note that special characters inside the filename are \"escaped\" ( <code>/</code> for instance ).</p> <p>Here is an exmaple of a simple unary predicate: <code>kb_callable</code>. The example demonstrates that the code \"entity\" in <code>pkg/ratelimit/result_test.go</code> is callbale. That is, a method, function or lambda.</p> <p>Atom predicates are prefixed with kb for knowledge base.</p> <p>Example</p> <pre><code>%\n% this is how a code fact looks\n%\nkb_callable( startloc_47_17_endloc_47_21_pkg_slash_ratelimit_slash_result_test_dot_go ).\n</code></pre> <p>The variables' order aims to be understood from context. Here are the API predicates related to calls:  </p> <p>Calls</p> <pre><code>kb_arg_i_for_call( Arg, Index, Call ).\n</code></pre> <p>Predicates that are not related to the actual code base, are prefixed with <code>utils_</code>, and they are considered to be an integral part of the API:</p> <p>Predicate: utils_arg_for_call / 2</p> <pre><code>% This is the actual implementation in the code\nutils_arg_for_call( Arg, Call ).\n</code></pre>"},{"location":"getting_started/ci_cd/","title":"CI/CD","text":"<p>Scan your code on every push / pull request - it's that fast. Your code never leaves the workflow. It is not logged anywhere. We don't even have a database \ud83d\ude09. There are no incremental scans, we care about your privacy, and don't cache any part of your code.</p> <p>Note</p> <p>Currently, only GitHub Actions yaml flavor is supported. Please open an issue if you are using other pipelines.</p> <p>Simply copy this to your GitHub actions:</p> <pre><code>name: dhscanner-sast\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  run-dhscanner:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: clone dhscanner (with submodules)\n        run: |\n          git clone --recurse-submodules https://github.com/OrenGitHub/dhscanner\n          cd dhscanner\n          docker compose -f compose.rel.x64.yaml up -d\n\n      - name: checkout specific tag\n        uses: actions/checkout@v4\n\n      - name: send the whole repo to dhscanner\n        run: |\n          tar -cz . | curl -v -X POST \\\n            -H \"X-Code-Sent-To-External-Server: false\" \\\n            -H \"Content-Type: application/octet-stream\" \\\n            --data-binary @- http://127.0.0.1:443/ &gt; output.sarif\n\n      - name: Upload SARIF results\n        uses: github/codeql-action/upload-sarif@v3\n        with:\n          sarif_file: output.sarif\n\n      - name: fail workflow if sarif contains findings\n        run: |\n          if jq '.runs[].results | length &gt; 0' output.sarif | grep -q 'true'; then\n            echo \"Sarif findings detected, failing the workflow\"\n            exit 1\n          fi\n</code></pre>"},{"location":"getting_started/cli/","title":"CLI","text":"<p>Running dhscanner locally is easy - You just need docker: <pre><code>$ git clone --recurse-submodules https://github.com/OrenGitHub/dhscanner\n$ cd dhscanner\n$ docker compose -f compose.rel.x64.yaml up -d\n</code></pre> To test your code: <pre><code>$ cd to/the/repo/you/want/to/scan\n$ tar -cz . | curl -v -X POST -H \"X-Code-Sent-To-External-Server: false\" -H \"Content-Type: application/octet-stream\" --data-binary @- http://127.0.0.1:443/ &gt; output.sarif\n</code></pre></p>"},{"location":"getting_started/introduction/","title":"Introduction","text":"<p>Hi you magnificent thing ! We're glad to see you here !</p>"},{"location":"research/heavy_workloads/","title":"Heavy workloads","text":"<p>The Dhscanner team is happy to allocate our \"monstrous\" \ud83d\udc7b VPS !</p> <p>Note</p> <p>For non-commercial use scanning popular open source packages.</p> <p>If your local machine chokes on massive computation of complex queries, and you are intereted in collaboration, please open an issue</p>"},{"location":"research/scanning_at_scale/","title":"Scanning at scale","text":"<p>Are you trying to find malicious code at scale ? We like you already !</p> <p>Note</p> <p>Check the queries used for our CI/CD scanner. It's a great place to start.</p> <p>Let's write a simple query for counting minified functions. Don't worry if you're not a Prolog expert. You don't have to be. If you ever played Lego when you were a kid - you should be fine.</p> <p>Pro Tip</p> <p>Use any LLM you like to build Prolog queries from Dhscanner atoms</p> <p>Dhscanner accepts its queries as part of the <code>tar</code>-ed repo in a special <code>Prolog</code> file called <code>.dhscanner.queries</code>. It is shown below as a one-liner, but clearly, you can edit this file and paste the results of your vibe-coding session in a more readable format. Remember, you don't have to be a Prolog expert to write queries. Literally any ( untrained ) LLM will be happy to translate your English specification to a proper Prolog file. Now fasten your seat belt and let's launch our query:</p> <pre><code>$ cd to/the/repo/you/want/to/scan\n$ echo \"minified(N) :- findall(C,(kb_callable(C),kb_has_fqn(C,Fqn),string_length(Fqn,Len),Len =&lt; 2), L),length(L, N).\" &gt; .dhscanner.queries\n$ tar -cz . | curl -X POST -H \"X-Code-Sent-To-External-Server: false\" -H \"Content-Type: application/octet-stream\" -H \"X-Ignore-Testing-Code: true\" --data-binary @- http://127.0.0.1:8000/\n</code></pre>"}]}